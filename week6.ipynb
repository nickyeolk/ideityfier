{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Oxl2RSbFo6kg"
   },
   "source": [
    "# AIAP Week 6 - Building a Machine Learning Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5iH7qxHFo6kh"
   },
   "source": [
    "Welcome to the last week of our coursework! In this week, we will look at deploying a model we have built in previous weeks. Unlike past weeks, where the focus is on the development of a high-performing statistical model, we will look at how to properly use this model, to put it into a server, and let users use it without the need of opening up our Jupyter notebook.   \n",
    "    \n",
    " It is important to note that because of the nature of this week's assignment, the skills required will be slightly different from prior weeks. As always, feel free to engage your peers or any of us if you would like more information. __For those who are new to serving code__, do take the time to understand the underlying concepts instead of copying code. __For those with prior experience__, you might want to focus on serialising a model, dockers, or exploring big data tools that are not commonly seen in the typical software stack."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ds4aZ55Ho6kj"
   },
   "source": [
    "Goals for the week:\n",
    "1. To deploy an AI/Machine Learning application\n",
    "2. To create a reproducible project\n",
    "3. To prototype quickly and work smart i.e. look for existing open-source projects and improvise them based on your project needs\n",
    "4. To have fun :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Credits to Raimi Karim (batch 1 apprentice) for resources for the week."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zGT14PeEo6kk"
   },
   "source": [
    "## 1. Project Idea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the nature of this week's coursework is to build a simple machine learning app, the project will be more free form. Our approach is as follows: we will prepare a baseline problem statement with close hand-holding for people who have not had prior experience with software engineering to work on. If after approaching this toy example, you feel that you are capable of doing more, we warmly invite you to give it a try, and perhaps share with the class. If you feel that this is trivial, you may wish to attempt your own problem statement from the start.\n",
    "\n",
    "<font color=darkblue>Our baseline project will be printed in this colour - dark blue. Jupyter Lab users may not be able to see this colour.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L2VX7DHGo6km"
   },
   "source": [
    "Like any other app project, we begin with defining a good problem statement. Formulating a clear problem statement will help give clarity to the problem we are solving. A well defined problem statement now allows us to focus on engineering and model development later, which means less distraction and time wasted due to context switching.\n",
    "\n",
    "One way to think about problem statements are through the '5W/1H' approach. Where we answer the following questions:  \n",
    "  \n",
    "- **Who** experiences this problem? What are their characteristics?  \n",
    "- **What** is the actual problem?  \n",
    "- **Why** does this app solve the problem?  \n",
    "- **How** will it be implemented?  \n",
    "- **When, where** should it be deployed? (not relevant for this week)\n",
    "\n",
    "<font color=darkblue>For a baseline project, we will be attempting to build a fruit classifier, which attempts to classify 3 different types of fruits: apples, oranges and pears. Suppose we have someone who has difficulty identifying fruits. In that case, building this app will help him identify fruit appropriately.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qJ4_qNwYo6kn"
   },
   "source": [
    "## 2. Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NomqslWIUmVK"
   },
   "source": [
    "We now move on to the actual workflow of training the model. The below is a standard set of steps for a mini-project. However, depending what what you do, you might need some variation, so modify them to your needs at your own discretion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lM9PZw_-o6kp"
   },
   "source": [
    "### 2.1 Obtain data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lM9PZw_-o6kp"
   },
   "source": [
    "We begin by collecting the data that we wish to train on. In this step, think more about the data you will need - how much would you need, and in what form should it be? In some cases, the problem we want to solve might already have a clean dataset to work on. In other cases, pre-trained models make our problem easier, and hence we only need a small fraction of a full-fledge training data.  \n",
    "\n",
    "For problems where data might not be present, you might want to also think about how to collect and label data. <br/>\n",
    "\n",
    "<font color=darkblue>For our case, we will begin by collecting images of each of the 3 fruits. We will use Google's image search to crawl a few pages of images for each label. Luckily, there are already tools out there to help you crawl of images - you can use this [python package](https://github.com/hardikvasa/google-images-download), or alternatively, `fastai` library has a [`download_images`](https://docs.fast.ai/vision.data.html#download_images) method.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3w7ZZ-WXo6kq"
   },
   "source": [
    "### 2.2 Preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3w7ZZ-WXo6kq"
   },
   "source": [
    "After getting the data, the next step is to see if our data is clean, and can be fed into the model.\n",
    "\n",
    "Check if our data is clean involves checking for null values, extreme outliers, consistency of file names etc. This is dependent on the nature of your dataset. Sometimes it might also help to visualise your data.\n",
    "\n",
    "We would also like to split our data into train-validation-test sets to track if our trained model later performs as well on the validation/test set as it did on our training set.\n",
    "\n",
    "<font color=darkblue>In our case, we will like to split this dataset into train and test sets, using appropriate data loaders/generators to create labels of 0, 1 and 2 for the fruits (or otherwise appropriate). Using the appropriate library of your choice, preprocess the images with the right preprocessing methods - resizing into 224px, then doing a center crop, normalizing colour values (you can just divide by 255), and finally turning each image into a 3x244x244 tensor. You may also do additional augments if you please.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DE1dm5nUo6kr"
   },
   "source": [
    "### 2.3 Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DE1dm5nUo6kr"
   },
   "source": [
    "Train your model locally (on your computer) or in Google Colab. Once done, run a few tests on the test set, and see if it performs as well as in the training set. If you are not satisfied, you can retrain your model. Finally, export your model out with the appropriate format, and download the weights for future use. In most cases, you should look to run a transfer learning model on an already optimised model. For image models, you can try something like resnet50. There have been some discussion about transfer learning in text models too - models such as BERT and ELMo... yes we agree that the names are ridiculous.\n",
    "\n",
    "<font color=darkblue>In our case, let's begin with a pretrained resnet50 model - ample code examples should be available for both torchvision and Keras. Freeze all layers except the last, and replace that with a linear layer of output size 3, fed through a softmax loss function. Be weary of overfitting when you train your model.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xrcyd017o6kr"
   },
   "source": [
    "### 2.4 Deploy model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xrcyd017o6kr"
   },
   "source": [
    "You can start with a simple localhosted [Python Flask](http://flask.pocoo.org) app for the deployment of your model. In this Flask app, provide an HTML endpoint that allows a user to submit a datapoint, and provide a prediction. Ensure that a user is able to make calls to your API by providing an input. A simple way to test this would be through the Postman application.\n",
    "\n",
    "<font color=darkblue>We will use the PIL package to help process the image given into the appropriate format. Your endpoint should accept a 224x224 image, which PIL can convert into a numpy array to be ingested as a tensor into the model.\n",
    "\n",
    "Write a `@app.route` to take in a request from a user, and provide a prediction response to the user. For those who are new to applications, take some time to understand how web servers are designed, and specifically, what are routes  in the context of a Flask app.</font>\n",
    "\n",
    "For people who are more advanced, you could also deploy your model in the following environments:\n",
    "- **Server**\n",
    "  - Local\n",
    "  - Self-hosted (WSGI, Nginx)\n",
    "  - App Engine\n",
    "  \n",
    "- **Docker**\n",
    "- **Front-end browser-based**\n",
    "  - tensorflow.js + GitHub Pages\n",
    "- **Mobile (Android)** <br>\n",
    "  - Package as an APK for distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. A Little Bit More"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this next section, we will look at some other bits of application development that could be useful to know."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Unit Testing, Integration Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the space of software engineering, complex operations happening within apps, in conjunction with multiple engineers working on multiple areas, make application development a hairy and unstable process. To mitigate the risks of bugs appearing in production environments, we write thorough tests that, to the best of our ability, ensure the accuracy and stability of our code. \n",
    "\n",
    "We will not go into detail into this section as this lies in the domain of software engineering, but understand that in production environments, testing is key to stability of any app. In addition, we use approaches like test-driven development (TDD), as well as a mix of tests at different levels.\n",
    "\n",
    "It is interesting to note the inherent probabalistic nature of machine learning models - we are not going to get the right predictions every time. How do we ensure that our tests will ensure the correctness of our code in the probabalistic, flaky environment of machine learning? We don't exactly have a gold standard answer to this question right now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Documentation (Important - Submission Details)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documentation is extremely important to ensure that when we pass our code on to another analyst or engineer, they will know how to work with and modify the code for their own use. Especially given that AI Singapore needs highly reusable code and exchange of information between teams, we would like to set high standards for documentation.\n",
    "\n",
    "For this assignment, we would expect a basic level of documentation written in a `README.md` in your repository. This document should discuss what your app would do, and give basic instructions - lines of bash commands - that can guide a user to run your code base on his computer. The right way to do this is to ask a partner to try running your code from the GitHub repository. If it runs with your instructions, you're good to go.\n",
    "\n",
    "[Here's a good, simple README.md file.](https://github.com/berlotto/flask-app-template)\n",
    "\n",
    "__Submission__: to submit, create a NEW REPOSITORY this week inside [this new project folder](https://bitbucket.ai3.aisingapore.org:9443/projects/ABA/) and push your code instead. Be sure to include a README.md as well as a [.gitignore](https://www.gitignore.io/) (as discussed by Deepan a few weeks ago). Please __do not__ upload large datasets or model weights into the repository - we have limited server space!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9R1Ox_T0o6kt"
   },
   "source": [
    "## 4. Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9R1Ox_T0o6kt"
   },
   "source": [
    "These are some ideas to get you started:\n",
    "\n",
    "\n",
    "**Image**\n",
    "\n",
    "  - Classify flowers: https://www.tensorflow.org/hub/tutorials/image_retraining\n",
    "  - Classify pictures of food for mobile users that helps them to easily attach hashtags for their Instagram post.\n",
    "  - Create your home security camera that detects faces of your family members using Raspberry Pi and grants access.\n",
    "  - Classify if a picture is an item that can be recycled or not. \n",
    "  - Recognise mathematical equations using Optical Character Recognition.\n",
    "  - Singlish meme: Automatically caption pictures.\n",
    "  - Style transfer: Generate an image of a utopia given an input.\n",
    "\n",
    "**Text**\n",
    "  - Generate text https://www.tensorflow.org/tutorials/sequences/text_generation\n",
    "  - Summarise a code in 1 paragraph.\n",
    "  - Using POS tagging, summarise a research paper in 1 paragraph.\n",
    "  - Use NLP to generate a Jupyter notebook exercise for AIAP for the next week.\n",
    "  - Cluster AI Singapore's web pages into meaningful categories.\n",
    "  - Generate/classify fake news in Singapore.\n",
    "  - A Singlish aunty-chatbot for buying groceries.\n",
    "\n",
    "**Audio**\n",
    "  - Classify sounds https://www.tensorflow.org/tutorials/sequences/audio_recognition\n",
    "  - Classify between the different Chinese dialects.\n",
    "  - Speech-to-Text application that identifies the main keywords and googles them.\n",
    "  - Transpose a music from major to minor scale using recurrent neural networks.\n",
    "\n",
    "**Video**\n",
    "  - A better push-up/sit-ups counter (oops).\n",
    "  - Dance-Dance revolution.\n",
    "  - Control a character in a game using pose recognition."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "week6.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}